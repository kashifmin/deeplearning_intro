{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying MNIST digits\n",
    "![mnist digits](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/6a54f12d0f63c9bc.png)\n",
    "\n",
    "## Lets see how we can design a deep learning model to classify these digits\n",
    "- we learn to use tensorflow low level apis\n",
    "- we will try out single layer ANN and then go for deeper networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for loading data\n",
    "#### No need worry about this for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_digit/train-images-idx3-ubyte.gz\n",
      "Extracting mnist_digit/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_digit/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_digit/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "dataset = input_data.read_data_sets('mnist_digit', one_hot=True, validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.train.images.shape)\n",
    "print(dataset.test.images.shape)\n",
    "print(dataset.train.labels.shape)\n",
    "print(dataset.test.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets define a function to create single ANN layer\n",
    "- Variables are all the parameters that you want the training algorithm to determine for you\n",
    "- As we know, a ANN unit consists of weights and biases, and some activation function\n",
    "\n",
    "\n",
    "![ANN](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/d5222c6e3d15770a.png)\n",
    "\n",
    "# For simplicity, lets use a activation function known to us\n",
    "\n",
    "![ANN](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/604a9797da2a48d7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dense_layer(x, in_units, out_units):\n",
    "#     # in_units -> number of input connections to this layer\n",
    "#     # out_units -> number of neurons i.e outputs of this layer\n",
    "#     # weight matrix for this full layer\n",
    "#     # since there are in_unit neurons, the shape will be (in_units, out_units)\n",
    "#     W = tf.Variable(tf.random_normal((in_units, out_units)))\n",
    "#     # one bias for each neuron\n",
    "#     B = tf.Variable(tf.zeros([out_units]))\n",
    "    \n",
    "#     # take weighted sum of input, apply activation and return\n",
    "#     out = tf.matmul(x, W) + B\n",
    "#     return tf.nn.softmax(out)\n",
    "\n",
    "def dense_layer(x, in_units, out_units, activation=tf.nn.relu):\n",
    "    # in_units -> number of input connections to this layer\n",
    "    # out_units -> number of neurons i.e outputs of this layer\n",
    "    # weight matrix for this full layer\n",
    "    # since there are in_unit neurons, the shape will be (in_units, out_units)\n",
    "    W = tf.Variable(tf.random_normal((in_units, out_units)))\n",
    "    # one bias for each neuron\n",
    "    B = tf.Variable(tf.zeros([out_units]))\n",
    "    \n",
    "    # take weighted sum of input, apply activation and return\n",
    "    out = tf.matmul(x, W) + B\n",
    "    return activation(out)\n",
    "\n",
    "def simple_layer(x, in_units, out_units):\n",
    "    # in_units -> number of input connections to this layer\n",
    "    # out_units -> number of neurons i.e outputs of this layer\n",
    "    # weight matrix for this full layer\n",
    "    # since there are in_unit neurons, the shape will be (in_units, out_units)\n",
    "    W = tf.Variable(tf.random_normal((in_units, out_units)))\n",
    "    # one bias for each neuron\n",
    "    B = tf.Variable(tf.zeros([out_units]))\n",
    "    \n",
    "    return tf.matmul(x, W) + B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A visualization of weighted sum happening in a single layer\n",
    "\n",
    "\n",
    "![Weighted sum](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/21dabcf6d44e4d6f.png)\n",
    "\n",
    "![out](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/206327168bc85294.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here we define the actual ANN architecture\n",
    "- we make use of the functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place holder for unknown number of images of size 28*28\n",
    "X = tf.placeholder(tf.float32, shape=(None, 28*28))\n",
    "# place holder for labels##\n",
    "Y = tf.placeholder(tf.int32, shape=(None, 10))\n",
    "\n",
    "# simple single layer network\n",
    "logits = simple_layer(X, 784, 10)\n",
    "out = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "# two layer network\n",
    "# out = dense_layer(X, 784, 512)\n",
    "# logits = simple_layer(out, 512, 10)\n",
    "# out = tf.nn.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Y will contain actual labels, 'out' will contain the predicted labels*\n",
    "\n",
    "## Lots of tensorflow magic here..\n",
    "- we only need to tell tf, which loss function and optimizer to use\n",
    "- Broad set of optimizers available like Adam, Adagrad, GradientDescent etc\n",
    "\n",
    "## Cross entropy loss function\n",
    "_Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. So predicting a probability of .012 when the actual observation label is 1 would be bad and result in a high loss value. A perfect model would have a log loss of 0._\n",
    "\n",
    "![](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/1d8fc59e6a674f1c.png)\n",
    "\n",
    "# Gradient Descent\n",
    "\n",
    "![](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/34e9e76c7715b719.png)\n",
    "\n",
    "\n",
    "## softmax_cross_entropy_with_logits measures the probability error in discrete classification tasks in which the classes are mutually exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but we dont need to worry much about the mathematical formula\n",
    "# tf makes it easy!\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "# lets use the most common optimizer known to us\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "# here we define what we actually want to run during training\n",
    "# we want to minimize cross_entropy i.e diff b/w predicted and actual probabilities\n",
    "train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "# % of correct answers found in batch\n",
    "is_correct = tf.equal(tf.argmax(Y,1), tf.argmax(out,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new tensorflow session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let the training begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train Accuracy = 0.9453125 | Loss = 0.1268822\n",
      "Epoch 0 Test Accuracy = 0.9228 | Loss =  0.2932236\n",
      "----------------------------------------------------------------------\n",
      "Epoch 1000 Train Accuracy = 0.921875 | Loss = 0.37477785\n",
      "Epoch 1000 Test Accuracy = 0.921 | Loss =  0.29630587\n",
      "----------------------------------------------------------------------\n",
      "Epoch 2000 Train Accuracy = 0.9453125 | Loss = 0.190063\n",
      "Epoch 2000 Test Accuracy = 0.9222 | Loss =  0.29114234\n",
      "----------------------------------------------------------------------\n",
      "Epoch 3000 Train Accuracy = 0.9375 | Loss = 0.19934976\n",
      "Epoch 3000 Test Accuracy = 0.9223 | Loss =  0.29254723\n",
      "----------------------------------------------------------------------\n",
      "Epoch 4000 Train Accuracy = 0.9609375 | Loss = 0.14497551\n",
      "Epoch 4000 Test Accuracy = 0.9209 | Loss =  0.2931765\n",
      "----------------------------------------------------------------------\n",
      "Epoch 5000 Train Accuracy = 0.9375 | Loss = 0.28321114\n",
      "Epoch 5000 Test Accuracy = 0.9218 | Loss =  0.29549745\n",
      "----------------------------------------------------------------------\n",
      "Epoch 6000 Train Accuracy = 0.875 | Loss = 0.47012562\n",
      "Epoch 6000 Test Accuracy = 0.9217 | Loss =  0.2908315\n",
      "----------------------------------------------------------------------\n",
      "Epoch 7000 Train Accuracy = 0.890625 | Loss = 0.3065631\n",
      "Epoch 7000 Test Accuracy = 0.9231 | Loss =  0.2882809\n",
      "----------------------------------------------------------------------\n",
      "Epoch 8000 Train Accuracy = 0.921875 | Loss = 0.23979062\n",
      "Epoch 8000 Test Accuracy = 0.9239 | Loss =  0.28758287\n",
      "----------------------------------------------------------------------\n",
      "Epoch 9000 Train Accuracy = 0.9453125 | Loss = 0.19457178\n",
      "Epoch 9000 Test Accuracy = 0.9231 | Loss =  0.29046816\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10000\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    batchX, batchY = dataset.train.next_batch(batch_size)\n",
    "    for b in range(0, train_size // batch_size, batch_size):\n",
    "        sess.run([train_op], feed_dict={X: batchX, Y: batchY})\n",
    "        \n",
    "    if i % 1000 == 0:\n",
    "        res = sess.run([accuracy, loss], feed_dict={X: batchX, Y: batchY})\n",
    "        print('Epoch', i, 'Train Accuracy =', res[0], '| Loss =', res[1])\n",
    "        res = sess.run([accuracy, loss], feed_dict={X: dataset.test.images, Y: dataset.test.labels})\n",
    "        print('Epoch', i, 'Test Accuracy =', res[0], '| Loss = ', res[1])\n",
    "        print('-'*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets go DEEP\n",
    "\n",
    "![deep](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/77bc41f211c9fb29.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Info\n",
    "\n",
    "# Activation Functions\n",
    "\n",
    "\n",
    "![sigmoid](https://cdn-images-1.medium.com/max/1600/1*XxxiA0jJvPrHEJHD4z893g.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
